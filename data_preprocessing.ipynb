{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.image\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from depth import __version__\n",
    "from depth.apis import set_random_seed, train_depther\n",
    "from depth.datasets import build_dataset\n",
    "from depth.models import build_depther\n",
    "from depth.utils import collect_env, get_root_logger\n",
    "from mmcv.runner import init_dist\n",
    "from mmcv.utils import Config, DictAction, get_git_hash\n",
    "from tqdm import tqdm\n",
    "\n",
    "# matplotlib.image.imsave('name.png', array)\n",
    "# im = Image.fromarray(data[0, 0], mode=\"F\").convert(\"RGB\")\n",
    "# im.save(f\"{fname.split('.')[0]}.jpeg\")\n",
    "\n",
    "# ├── data\n",
    "# │   ├── custom\n",
    "# │   │   ├── train\n",
    "# │   │   │   ├── rgb\n",
    "# │   │   │   │   ├── 0.xxx\n",
    "# │   │   │   │   ├── 1.xxx\n",
    "# │   │   │   │   ├── 2.xxx\n",
    "# │   │   │   ├── depth\n",
    "# │   │   │   │   ├── 0.xxx\n",
    "# │   │   │   │   ├── 1.xxx\n",
    "# │   │   │   │   ├── 2.xxx\n",
    "# │   │   ├── val\n",
    "# │   │   │   ...\n",
    "# │   │   │   ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tasks found: ['block-insertion' 'manipulating-rope']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:11<00:00,  2.69it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.12it/s]\n",
      "100%|██████████| 1000/1000 [25:55<00:00,  1.56s/it]\n",
      "100%|██████████| 100/100 [02:38<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "data_root = Path(\"../dataset/depth\")\n",
    "\n",
    "\n",
    "def transform_task_dataset_to_images(task_dataset_root, image_dataset_root):\n",
    "    all_subdirectories = [f.stem for f in task_dataset_root.iterdir() if f.is_dir()]\n",
    "    task_names = np.unique(\n",
    "        [\n",
    "            \"-\".join(f.split(\"-\")[:2])\n",
    "            for f in all_subdirectories\n",
    "            if \"train\" in f or \"test\" in f\n",
    "        ]\n",
    "    )\n",
    "    print(f\"{len(task_names)} tasks found: {task_names}\")\n",
    "    for task_name in task_names:\n",
    "        for _mode in [\"train\", \"test\"]:\n",
    "            mode = _mode if _mode == \"train\" else \"val\"\n",
    "            dataset_root = task_dataset_root / f\"{task_name}-{_mode}/\"\n",
    "\n",
    "            color_files = sorted(\n",
    "                [f for f in (dataset_root / \"color\").glob(\"**/*\") if f.is_file()]\n",
    "            )\n",
    "            depth_files = sorted(\n",
    "                [f for f in (dataset_root / \"depth\").glob(\"**/*\") if f.is_file()]\n",
    "            )\n",
    "\n",
    "            for color_file, depth_file in tqdm(\n",
    "                zip(color_files, depth_files), total=len(color_files)\n",
    "            ):\n",
    "                color_images = pickle.load(open(color_file, \"rb\"))\n",
    "                depth_images = pickle.load(open(depth_file, \"rb\"))\n",
    "                color_images_shape = color_images.shape[-3:]\n",
    "\n",
    "                color_images = color_images.reshape((-1, *color_images_shape))\n",
    "                depth_images = depth_images.reshape((-1, *color_images_shape[:-1]))\n",
    "\n",
    "                nb_image_per_color_files = len(color_images)\n",
    "                nb_image_per_depth_files = len(depth_images)\n",
    "                assert nb_image_per_color_files == nb_image_per_depth_files\n",
    "\n",
    "                for index, (color_image, depth_image) in enumerate(\n",
    "                    zip(color_images, depth_images)\n",
    "                ):\n",
    "                    filename_color = color_file.stem\n",
    "                    filename_depth = depth_file.stem\n",
    "                    assert (\n",
    "                        filename_color == filename_depth\n",
    "                    ), f\"got 2 different filenames: {filename_color} and {filename_depth}\"\n",
    "                    (image_dataset_root / mode / \"rgb\").mkdir(\n",
    "                        parents=True, exist_ok=True\n",
    "                    )\n",
    "                    (image_dataset_root / mode / \"depth\").mkdir(\n",
    "                        parents=True, exist_ok=True\n",
    "                    )\n",
    "                    matplotlib.image.imsave(\n",
    "                        image_dataset_root\n",
    "                        / mode\n",
    "                        / \"rgb\"\n",
    "                        / (filename_color.split(\"-\")[0] + f\"-{task_name}-{index}.png\"),\n",
    "                        color_image,\n",
    "                    )\n",
    "                    matplotlib.image.imsave(\n",
    "                        image_dataset_root\n",
    "                        / mode\n",
    "                        / \"depth\"\n",
    "                        / (filename_color.split(\"-\")[0] + f\"-{task_name}-{index}.png\"),\n",
    "                        depth_image,\n",
    "                    )\n",
    "\n",
    "\n",
    "transform_task_dataset_to_images(Path(\"dataset\"), Path(\"dataset/depth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = \"depth_custom_dataset.py\"\n",
    "# load_from = \"checkpoints/binsformer_swint_nyu_converted.pth\"\n",
    "config = \"finetune_adabins_efnetb5ap_nyu_24e.py\"\n",
    "load_from = \"checkpoints/adabins_efnetb5_nyu.pth\"\n",
    "work_dir = None\n",
    "resume_from = None\n",
    "no_validate = False\n",
    "gpus = None\n",
    "gpu_ids = None\n",
    "seed = 42\n",
    "deterministic = True\n",
    "options = None\n",
    "launcher = \"none\"\n",
    "local_rank = 0\n",
    "\n",
    "if 'LOCAL_RANK' not in os.environ:\n",
    "    os.environ['LOCAL_RANK'] = str(local_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 18:53:20,480 - depth - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]\n",
      "CUDA available: False\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.8.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.9.0\n",
      "OpenCV: 4.7.0\n",
      "MMCV: 1.5.0\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 10.2\n",
      "Depth: 0.1.1+5f32548\n",
      "------------------------------------------------------------\n",
      "\n",
      "2023-01-01 18:53:20,483 - depth - INFO - Distributed training: False\n",
      "2023-01-01 18:53:20,865 - depth - INFO - Config:\n",
      "model = dict(\n",
      "    type='DepthEncoderDecoder',\n",
      "    backbone=dict(type='EfficientNet'),\n",
      "    decode_head=dict(\n",
      "        type='AdabinsHead',\n",
      "        in_channels=[24, 40, 64, 176, 2048],\n",
      "        up_sample_channels=[128, 256, 512, 1024, 2048],\n",
      "        channels=128,\n",
      "        align_corners=True,\n",
      "        loss_decode=dict(type='SigLoss', valid_mask=True, loss_weight=10),\n",
      "        min_depth=0.001,\n",
      "        max_depth=10,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook', by_epoch=False),\n",
      "        dict(type='TensorboardLoggerHook')\n",
      "    ])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/adabins_efnetb5_nyu.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "max_lr = 0.000357\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.000357,\n",
      "    betas=(0.95, 0.99),\n",
      "    weight_decay=0.1,\n",
      "    paramwise_cfg=dict(custom_keys=dict(decode_head=dict(lr_mult=10))))\n",
      "lr_config = dict(\n",
      "    policy='OneCycle',\n",
      "    max_lr=0.000357,\n",
      "    div_factor=25,\n",
      "    final_div_factor=100,\n",
      "    by_epoch=False)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=24, max_iters=24)\n",
      "checkpoint_config = dict(by_epoch=True, max_keep_ckpts=2, interval=1)\n",
      "evaluation = dict(by_epoch=True, interval=1, pre_eval=True)\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "find_unused_parameters = True\n",
      "SyncBN = True\n",
      "dataset_type = 'CustomDepthDataset'\n",
      "data_root = 'dataset/depth/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (416, 544)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='DepthLoadAnnotations'),\n",
      "    dict(type='NYUCrop', depth=True),\n",
      "    dict(type='RandomRotate', prob=0.5, degree=2.5),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='RandomCrop', crop_size=(416, 544)),\n",
      "    dict(\n",
      "        type='ColorAug',\n",
      "        prob=1,\n",
      "        gamma_range=[0.9, 1.1],\n",
      "        brightness_range=[0.75, 1.25],\n",
      "        color_range=[0.9, 1.1]),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'depth_gt'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', img_scale=(480, 640)),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(480, 640),\n",
      "        flip=True,\n",
      "        flip_direction='horizontal',\n",
      "        transforms=[\n",
      "            dict(type='RandomFlip', direction='horizontal'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=16,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CustomDepthDataset',\n",
      "        data_root='dataset/depth//train',\n",
      "        depth_scale=1,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='DepthLoadAnnotations'),\n",
      "            dict(type='NYUCrop', depth=True),\n",
      "            dict(type='RandomRotate', prob=0.5, degree=2.5),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='RandomCrop', crop_size=(416, 544)),\n",
      "            dict(\n",
      "                type='ColorAug',\n",
      "                prob=1,\n",
      "                gamma_range=[0.9, 1.1],\n",
      "                brightness_range=[0.75, 1.25],\n",
      "                color_range=[0.9, 1.1]),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'depth_gt'])\n",
      "        ],\n",
      "        min_depth=0.001,\n",
      "        max_depth=10),\n",
      "    val=dict(\n",
      "        type='CustomDepthDataset',\n",
      "        data_root='dataset/depth//val',\n",
      "        depth_scale=1,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(480, 640)),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(480, 640),\n",
      "                flip=True,\n",
      "                flip_direction='horizontal',\n",
      "                transforms=[\n",
      "                    dict(type='RandomFlip', direction='horizontal'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        min_depth=0.001,\n",
      "        max_depth=10),\n",
      "    test=dict(\n",
      "        type='CustomDepthDataset',\n",
      "        data_root='dataset/depth//val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(480, 640)),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(480, 640),\n",
      "                flip=True,\n",
      "                flip_direction='horizontal',\n",
      "                transforms=[\n",
      "                    dict(type='RandomFlip', direction='horizontal'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        min_depth=0.001,\n",
      "        max_depth=10))\n",
      "momentum_config = dict(policy='OneCycle')\n",
      "work_dir = './work_dirs/finetune_adabins_efnetb5ap_nyu_24e'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2023-01-01 18:53:20,867 - depth - INFO - Set random seed to 42, deterministic: True\n",
      "Using cache found in /home/matias/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "2023-01-01 18:53:23,915 - depth - INFO - DepthEncoderDecoder(\n",
      "  (backbone): EfficientNet(\n",
      "    (original_model): GenEfficientNet(\n",
      "      (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn1): SyncBatchNorm(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (blocks): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "            (bn1): SyncBatchNorm(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): SyncBatchNorm(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): Identity()\n",
      "          )\n",
      "          (1): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (bn1): SyncBatchNorm(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): SyncBatchNorm(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): Identity()\n",
      "          )\n",
      "          (2): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (bn1): SyncBatchNorm(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): SyncBatchNorm(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "            (bn2): SyncBatchNorm(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2dSame(240, 240, kernel_size=(5, 5), stride=(2, 2), groups=240, bias=False)\n",
      "            (bn2): SyncBatchNorm(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
      "            (bn2): SyncBatchNorm(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "            (bn2): SyncBatchNorm(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2dSame(1056, 1056, kernel_size=(5, 5), stride=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): SyncBatchNorm(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (7): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (8): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): SyncBatchNorm(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): SyncBatchNorm(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): SyncBatchNorm(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): SyncBatchNorm(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act2): SiLU(inplace=True)\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): SyncBatchNorm(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_head): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): SyncBatchNorm(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): SiLU(inplace=True)\n",
      "      (global_pool): Identity()\n",
      "      (classifier): Identity()\n",
      "    )\n",
      "  )\n",
      "  (decode_head): AdabinsHead(\n",
      "    align_corners=True\n",
      "    (loss_decode): SigLoss()\n",
      "    (conv_depth): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (conv_list): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): UpSample(\n",
      "        (convA): ConvModule(\n",
      "          (conv): Conv2d(2224, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (convB): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): UpSample(\n",
      "        (convA): ConvModule(\n",
      "          (conv): Conv2d(1088, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (convB): ConvModule(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): UpSample(\n",
      "        (convA): ConvModule(\n",
      "          (conv): Conv2d(552, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (convB): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): UpSample(\n",
      "        (convA): ConvModule(\n",
      "          (conv): Conv2d(280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (convB): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (loss_chamfer): BinsChamferLoss()\n",
      "    (decode_final_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (adaptive_bins_layer): mViT(\n",
      "      (patch_transformer): PatchTransformerEncoder(\n",
      "        (transformer_encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (embedding_convPxP): Conv2d(128, 128, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dot_product_layer): PixelWiseDotProduct()\n",
      "      (conv3x3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (regressor): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2023-01-01 18:53:23,969 - depth - INFO - Loaded 31956 images.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12268/737760929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mno_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     meta=meta)\n\u001b[0m",
      "\u001b[0;32m~/RECVIS/RECVIS-transporter-networks/Monocular-Depth-Estimation-Toolbox/depth/apis/train.py\u001b[0m in \u001b[0;36mtrain_depther\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         model = MMDataParallel(\n\u001b[0;32m---> 70\u001b[0;31m             model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# build runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RECVIS/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config)\n",
    "if options is not None:\n",
    "    cfg.merge_from_dict(options)\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# work_dir is determined in this priority: CLI > segment in file > filename\n",
    "if work_dir is not None:\n",
    "    # update configs according to CLI args if work_dir is not None\n",
    "    cfg.work_dir = work_dir\n",
    "elif cfg.get('work_dir', None) is None:\n",
    "    # use config filename as default work_dir if cfg.work_dir is None\n",
    "    cfg.work_dir = osp.join('./work_dirs',\n",
    "                            osp.splitext(osp.basename(config))[0])\n",
    "if load_from is not None:\n",
    "    cfg.load_from = load_from\n",
    "if resume_from is not None:\n",
    "    cfg.resume_from = resume_from\n",
    "if gpu_ids is not None:\n",
    "    cfg.gpu_ids = gpu_ids\n",
    "else:\n",
    "    cfg.gpu_ids = range(1) if gpus is None else range(gpus)\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "if launcher == 'none':\n",
    "    distributed = False\n",
    "# else:\n",
    "#     distributed = True\n",
    "#     init_dist(launcher, **cfg.dist_params)\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(config)))\n",
    "# init the logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# set random seeds\n",
    "if seed is not None:\n",
    "    logger.info(f'Set random seed to {seed}, deterministic: '\n",
    "                f'{deterministic}')\n",
    "    set_random_seed(seed, deterministic=deterministic)\n",
    "cfg.seed = seed\n",
    "meta['seed'] = seed\n",
    "meta['exp_name'] = osp.basename(config)\n",
    "\n",
    "model = build_depther(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "\n",
    "# NOTE: set all the bn to syncbn\n",
    "import torch.nn as nn\n",
    "if cfg.get('SyncBN', False):\n",
    "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "logger.info(model)\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    val_dataset.pipeline = cfg.data.train.pipeline\n",
    "    datasets.append(build_dataset(val_dataset))\n",
    "if cfg.checkpoint_config is not None:\n",
    "    # save depth version, config file content and class names in\n",
    "    # checkpoints as meta data\n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        depth_version=f'{__version__}+{get_git_hash()[:7]}',\n",
    "        config=cfg.pretty_text)\n",
    "# passing checkpoint meta for saving best checkpoint\n",
    "meta.update(cfg.checkpoint_config.meta)\n",
    "train_depther(\n",
    "    model,\n",
    "    datasets,\n",
    "    cfg,\n",
    "    distributed=distributed,\n",
    "    validate=(not no_validate),\n",
    "    timestamp=timestamp,\n",
    "    meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CustomDepthDataset',\n",
       " 'data_root': 'dataset/depth//train',\n",
       " 'depth_scale': 1,\n",
       " 'split': 'nyu_train.txt',\n",
       " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'DepthLoadAnnotations'},\n",
       "  {'type': 'NYUCrop', 'depth': True},\n",
       "  {'type': 'RandomRotate', 'prob': 0.5, 'degree': 2.5},\n",
       "  {'type': 'RandomFlip', 'prob': 0.5},\n",
       "  {'type': 'RandomCrop', 'crop_size': (416, 544)},\n",
       "  {'type': 'ColorAug',\n",
       "   'prob': 1,\n",
       "   'gamma_range': [0.9, 1.1],\n",
       "   'brightness_range': [0.75, 1.25],\n",
       "   'color_range': [0.9, 1.1]},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_rgb': True},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'depth_gt']}],\n",
       " 'garg_crop': False,\n",
       " 'eigen_crop': True,\n",
       " 'min_depth': 0.001,\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RECVIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8a35b37cfca56025b4114937c56ce998f435935297814a19b312b9adb4d0b6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
